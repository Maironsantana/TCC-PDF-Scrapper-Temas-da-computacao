{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6sI6wSk17_GS",
        "BrEicCXnUHTh",
        "i_gGZ1yVfHbc"
      ],
      "mount_file_id": "18lHfLgm0AmQZBGugzX3n5tluGIqxc3aj",
      "authorship_tag": "ABX9TyNTQ34qQIO+M/3Ovadq3iC/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maironsantana/TCC-Sistema-de-Recomendacao-Professores/blob/main/TCC_Sistema_Recomendativo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bibliotecas"
      ],
      "metadata": {
        "id": "3eeCk6JR05EK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBm0ER8NdAnI"
      },
      "outputs": [],
      "source": [
        "!pip install unicode\n",
        "import unicodedata\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Carregando Dataframe"
      ],
      "metadata": {
        "id": "Gg-ICsuw09Mj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fazendo upload do arquivo csv com a seguinte estrutura:\n",
        "#Orientador / Coorientador / \"Tema_1\" / \"Tema_2\" / \"Tema_3\" / \"Tema_4\" / ... (Substituindo os \"temas\" pelo nome do tema propriamente dito)\n",
        "#Onde cada linha do csv é um trabalho com seus orientadores, coorientadores e valores de porcentagem em cada tema (Usar o script para classificar trabalhos)\n",
        "\n",
        "TCCsDataset = pd.read_csv('/content/drive/MyDrive/.....')"
      ],
      "metadata": {
        "id": "KT3o9cEM04ti"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preenchendo trabalhos sem coorientadores com \"-\"\n",
        "TCCsDataset = TCCsDataset.fillna(\"-\")\n",
        "TCCsDataset"
      ],
      "metadata": {
        "id": "B9z0wAij2UYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A seguir, iremos buscar os 3 temas com maiores valores de porcentagem, assim cada trabalho terá 3 temas relacionados"
      ],
      "metadata": {
        "id": "ce4_SNFHaR21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista para armazenar os novos dados\n",
        "novo_array_de_trabalhos = []\n",
        "\n",
        "# Itera sobre as linhas do DataFrame\n",
        "for _, linha in TCCsDataset.iterrows():\n",
        "    # Extrai os nomes dos orientadores e coorientadores\n",
        "    orientador = linha['Orientador']\n",
        "    coorientador = linha['Coorientador']\n",
        "\n",
        "    # Cria um dicionário para armazenar as pontuações dos temas\n",
        "    temas_pontuacoes = {tema: linha[tema] for tema in TCCsDataset.columns[2:]}\n",
        "\n",
        "    # Obtém os cinco temas de maior pontuação\n",
        "    temas_mais_pontuados = sorted(temas_pontuacoes, key=temas_pontuacoes.get, reverse=True)[:5]\n",
        "\n",
        "    # Adiciona os dados ao novo DataFrame\n",
        "    novo_array_de_trabalhos.append({\n",
        "        'Orientador': orientador,\n",
        "        'Coorientador': coorientador,\n",
        "        'Tema1': temas_mais_pontuados[0],\n",
        "        'Tema2': temas_mais_pontuados[1],\n",
        "        'Tema3': temas_mais_pontuados[2],\n",
        "    })\n",
        "\n",
        "# Cria um novo DataFrame com os dados gerados\n",
        "novo_TCCsDataset = pd.DataFrame(novo_array_de_trabalhos)\n",
        "\n",
        "# Exibe o novo DataFrame\n",
        "novo_TCCsDataset\n"
      ],
      "metadata": {
        "id": "B4nsq8oh3WB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para descobrir o tempo de experiência de um professor em um determinado tema, e feito uma relação entre Tema - Subárea da Computação - Disciplina. Sabendo o tempo de experiencia de um professor em uma determinada disciplina é possivel descobrir o mesmo para um tema da computação."
      ],
      "metadata": {
        "id": "KuGZaJt-bEnr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importação de um CSV fazendo a relação de uma matéra com a subárea da computação\n",
        "relacaoDisciplinaSubarea = pd.read_csv('/content/drive/MyDrive/....', index_col='MATÉRIA')\n",
        "relacaoDisciplinaSubarea"
      ],
      "metadata": {
        "id": "-hqSMW_7yXJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importação de um CSV fazendo a relação de um tema com a subárea da computação\n",
        "relacaoTopicoSubarea = pd.read_csv('/content/drive/MyDrive/....', index_col='TÓPICO')\n",
        "relacaoTopicoSubarea"
      ],
      "metadata": {
        "id": "BEGyPh8IHYSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importando um CSV contendo a relação professor X MATÉRIA, onde cada célula possui o valor em horas do professor na MATÉRIA\n",
        "DatasetHorasDisciplinas = pd.read_csv('/content/drive/MyDrive/....', index_col='NOME_PROFESSOR')\n",
        "DatasetHorasDisciplinas"
      ],
      "metadata": {
        "id": "eVSMpfblzlbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Algoritmo para calcular o tempo de experiência em horas de um professor na SUBÁREA da computação\n",
        "DicionarioHorasSubareas = {}\n",
        "\n",
        "for index, row in DatasetHorasDisciplinas.iterrows():\n",
        "  for column, value in row.items():\n",
        "    if index not in DicionarioHorasSubareas:\n",
        "      DicionarioHorasSubareas[index] = {}\n",
        "    if relacaoDisciplinaSubarea.loc[column, 'SUBÁREA'] in DicionarioHorasSubareas[index]:\n",
        "      DicionarioHorasSubareas[index][relacaoDisciplinaSubarea.loc[column, 'SUBÁREA']] += value\n",
        "    else:\n",
        "      DicionarioHorasSubareas[index][relacaoDisciplinaSubarea.loc[column, 'SUBÁREA']] = value\n",
        "\n",
        "\n",
        "#Temos agora um dataset com a relação professor X SUBÁREA\n",
        "DatasetHorasSubareas = pd.DataFrame(DicionarioHorasSubareas)\n",
        "DatasetHorasSubareas = DatasetHorasSubareas.transpose()\n",
        "#DROPANDO MATERIAS SEM CLASSIFICAÇÃO\n",
        "DatasetHorasSubareas = DatasetHorasSubareas.drop('-', axis=1)\n",
        "DatasetHorasSubareas"
      ],
      "metadata": {
        "id": "rBYfYjDw4EJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Algoritmo para calcular o tempo de experiência em horas de um professor no TEMA da computação\n",
        "DicionarioHorasTopicos = {}\n",
        "\n",
        "for index, row in relacaoTopicoSubarea.iterrows():\n",
        "  for professor, subarea in DatasetHorasSubareas.iterrows():\n",
        "    if professor not in DicionarioHorasTopicos:\n",
        "      DicionarioHorasTopicos[professor] = {}\n",
        "\n",
        "    if row['SUBÁREA'] not in DatasetHorasSubareas.columns:\n",
        "      DicionarioHorasTopicos[professor][index] = 0\n",
        "    else:\n",
        "      DicionarioHorasTopicos[professor][index] = subarea[row['SUBÁREA']]\n",
        "\n",
        "#Temos agora um dataset com a relação professor X TEMA\n",
        "DatasetHorasTopicos = pd.DataFrame(DicionarioHorasTopicos)\n",
        "DatasetHorasTopicos = DatasetHorasTopicos.transpose()\n",
        "DatasetHorasTopicos"
      ],
      "metadata": {
        "id": "QJ_g6p312f5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Análise dos dados"
      ],
      "metadata": {
        "id": "69JTQlP4UY8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenar as colunas de temas em uma única série\n",
        "temas_series = pd.concat([novo_TCCsDataset['Tema1'], novo_TCCsDataset['Tema2'], novo_TCCsDataset['Tema3']])\n",
        "\n",
        "# Calcular a contagem total de aparições para cada tema\n",
        "contagem_temas = temas_series.value_counts()\n",
        "\n",
        "# Calcular a porcentagem de aparição de cada tema\n",
        "porcentagem_temas = (contagem_temas / 82)\n",
        "\n",
        "# Ordenar os temas por porcentagem\n",
        "porcentagem_temas = porcentagem_temas.sort_values(ascending=False)\n",
        "df_maiores_valores = porcentagem_temas.head(10)\n",
        "\n",
        "# Criar um gráfico de barras\n",
        "plt.figure(figsize=(10, 6))\n",
        "df_maiores_valores.plot(kind='bar')\n",
        "plt.xlabel('TÓPICOS')\n",
        "plt.ylabel('PORCENTAGEM DE TRABALHOS')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "dSQW6MZV4uqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PARTICIPAÇÃO DOS PROFESSORES NOS TCCS APRESENTADOS\n",
        "orientadores_unicos = TCCsDataset['Orientador'].append(TCCsDataset['Coorientador']).unique()\n",
        "\n",
        "df_porcentagens_orientadores = pd.DataFrame(columns=['Porcentagem de Aparição'])\n",
        "\n",
        "for orientador in orientadores_unicos:\n",
        "    total_aparicoes = ((TCCsDataset['Orientador'] == orientador) | (TCCsDataset['Coorientador'] == orientador)).sum()\n",
        "\n",
        "    porcentagem = total_aparicoes / len(TCCsDataset)\n",
        "\n",
        "    df_porcentagens_orientadores.loc[orientador] = [porcentagem]\n",
        "\n",
        "df_porcentagens_orientadores"
      ],
      "metadata": {
        "id": "ekL64GEpTz5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pontuação individual"
      ],
      "metadata": {
        "id": "j-oaJ4lh8JRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#é feita uma soma para descobrir o valor total de participação de cada professor nos temas\n",
        "PontuacaoTCC = TCCsDataset\n",
        "dataset_columns = PontuacaoTCC.columns[2:]\n",
        "dataset_columns\n",
        "\n",
        "total_professores = {}\n",
        "\n",
        "for index, row in PontuacaoTCC.iterrows():\n",
        "  orientador = row['Orientador']\n",
        "  coorientador = row['Coorientador']\n",
        "\n",
        "\n",
        "  if orientador not in total_professores:\n",
        "    total_professores[orientador] = {}\n",
        "    total_professores[orientador] = row[dataset_columns]\n",
        "  elif orientador in total_professores:\n",
        "    total_professores[orientador] += row[dataset_columns]\n",
        "\n",
        "  if coorientador not in total_professores:\n",
        "    total_professores[coorientador] = {}\n",
        "    total_professores[coorientador] = row[dataset_columns]\n",
        "  elif coorientador in total_professores:\n",
        "    total_professores[coorientador] += row[dataset_columns]\n",
        "\n",
        "\n",
        "total_orientadores_df = pd.DataFrame(total_professores)\n",
        "total_orientadores_df = total_orientadores_df.drop(columns = '-', axis=1)\n",
        "\n",
        "total_orientadores_df"
      ],
      "metadata": {
        "id": "-1_rHjjY-bbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Montagem da tabela de probabilidade. Cada professor terá um valor de porcentagem calculado a partir do valor de trabalhos no tema que ele orientou, dividido pelo total de trabalhos no tema\n",
        "\n",
        "PontuacaoTCC = total_orientadores_df\n",
        "\n",
        "def calcular_porcentagem(linha):\n",
        "    soma = linha.sum()\n",
        "    if soma == 0:\n",
        "        return linha  # Evita a divisão por zero, mantendo os valores originais\n",
        "    return (linha / soma)\n",
        "\n",
        "dataset_columns = PontuacaoTCC.apply(calcular_porcentagem, axis=1)\n",
        "\n",
        "dataset_columns"
      ],
      "metadata": {
        "id": "Jw9Q-yNq6TTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adição de valores ficticios para evitar futuramente multiplicações por 0 no algoritmo\n",
        "TCCDataframe = dataset_columns.transpose()\n",
        "TCCDataframe = TCCDataframe + 0.001\n",
        "TCCDataframe"
      ],
      "metadata": {
        "id": "Jx8Or19GO7Kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adição de valores ficticios para evitar multiplicações por 0 no algoritmo\n",
        "DatasetHorasTopicos = DatasetHorasTopicos + 1\n",
        "DatasetHorasTopicos"
      ],
      "metadata": {
        "id": "vZt8UP6WcmM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculo do valor de probabilidade do professor relacionado a quantidade de horas que ele ensinou na matéria/tema\n",
        "TopicosHorasDataframe = DatasetHorasTopicos.div(DatasetHorasTopicos.sum(axis=0).replace(0,1), axis=1)\n",
        "\n",
        "def formatar_nome_coluna(nome):\n",
        "    nome = nome.lower()  # Converte para minúsculas\n",
        "    nome = nome.replace(\" \", \"_\")  # Substitui espaços por underscores\n",
        "    nome = ''.join((c for c in unicodedata.normalize('NFD', nome) if unicodedata.category(c) != 'Mn'))  # Remove acentos\n",
        "    return nome\n",
        "\n",
        "TopicosHorasDataframe.columns = [formatar_nome_coluna(coluna) for coluna in TopicosHorasDataframe.columns]\n",
        "TopicosHorasDataframe"
      ],
      "metadata": {
        "id": "xUQcNMIVbKMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#É feito o merge de ambos os datasets Orientação e Horas ministradas\n",
        "\n",
        "professores = list(set(TCCDataframe.index))\n",
        "topicos = list(set(TCCDataframe.columns))\n",
        "\n",
        "colunas = pd.MultiIndex.from_product([topicos, ['Participação', 'Horas Ministradas']])\n",
        "\n",
        "TeachersCrossMerged = pd.DataFrame(1, index=professores, columns=colunas)\n",
        "\n",
        "for professor in professores:\n",
        "  for topico in topicos:\n",
        "    if topico in TCCDataframe.columns and professor in TCCDataframe.index:\n",
        "      tcc_value = TCCDataframe.at[professor, topico]\n",
        "      TeachersCrossMerged.at[professor, (topico, 'Participação')] = tcc_value\n",
        "    if topico in TopicosHorasDataframe.columns and professor in TopicosHorasDataframe.index:\n",
        "      hours_value = TopicosHorasDataframe.at[professor, topico]\n",
        "      TeachersCrossMerged.at[professor, (topico, 'Horas Ministradas')] = hours_value\n",
        "\n",
        "TeachersCrossMerged"
      ],
      "metadata": {
        "id": "fBNozhxUdx_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Algorítimo"
      ],
      "metadata": {
        "id": "BrEicCXnUHTh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primeiro modelo do algoritmo, com testes mockados"
      ],
      "metadata": {
        "id": "EGtIfWltgBly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#GERAR A RECOMENDAÇÃO\n",
        "def gerar_recomendação(assunto1, assunto2, assunto3):\n",
        "  recomendacao = {}\n",
        "  for index, row in TeachersCrossMerged.iterrows():\n",
        "    P_Assunto1 = TeachersCrossMerged.loc[index, (assunto1, 'Participação')]\n",
        "    H_Assunto1 = TeachersCrossMerged.loc[index, (assunto1, 'Horas Ministradas')]\n",
        "\n",
        "    P_Assunto2 = TeachersCrossMerged.loc[index, (assunto2, 'Participação')]\n",
        "    H_Assunto2 = TeachersCrossMerged.loc[index, (assunto2, 'Horas Ministradas')]\n",
        "\n",
        "    P_Assunto3 = TeachersCrossMerged.loc[index, (assunto3, 'Participação')]\n",
        "    H_Assunto3 = TeachersCrossMerged.loc[index, (assunto3, 'Horas Ministradas')]\n",
        "\n",
        "\n",
        "    P_total = df_porcentagens_orientadores.at[index, 'Porcentagem de Aparição']\n",
        "\n",
        "    P = P_total * P_Assunto1 * P_Assunto2 * P_Assunto3 * H_Assunto1 * H_Assunto2 * H_Assunto3\n",
        "    recomendacao[index] = P\n",
        "\n",
        "\n",
        "  return recomendacao\n",
        "\n",
        "#RESULTADO DA PREVISÃO\n",
        "previsao = gerar_recomendação('aprendizado_de_maquina', 'aprendizado_de_maquina', 'aprendizado_de_maquina')\n",
        "\n",
        "\n",
        "#CALCULO DA PORCENTAGEM\n",
        "soma_total = sum(previsao.values())\n",
        "\n",
        "porcentagens = {}\n",
        "for autor, resultado in previsao.items():\n",
        "    porcentagem = (resultado / soma_total) * 100\n",
        "    porcentagens[autor] = porcentagem\n",
        "\n",
        "porcentagens\n",
        "# previsao\n"
      ],
      "metadata": {
        "id": "546cZ27AQSHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def algoritmo_recomendacao(assunto1, assunto2, assunto3):\n",
        "  previsao = gerar_recomendação(assunto1, assunto2, assunto3)\n",
        "  series = pd.Series(previsao)\n",
        "  qtd = 5\n",
        "  melhores_professores = series.nlargest(5)\n",
        "  return melhores_professores\n",
        "\n",
        "algoritmo_recomendacao('complexidade_computacional', 'complexidade_computacional', 'complexidade_computacional')"
      ],
      "metadata": {
        "id": "JcgImkuhWzIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Validação"
      ],
      "metadata": {
        "id": "i_gGZ1yVfHbc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testes de validação para calcular a acurácia simples"
      ],
      "metadata": {
        "id": "ZbJPCEJPgH29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#SEPARAÇÃO DOS 13 ARTIGOS PARA TESTE\n",
        "\n",
        "contagem_orientadores = TCCsDataset['Orientador'].value_counts()\n",
        "\n",
        "total_test_items = 13\n",
        "orientador_proportions = contagem_orientadores / contagem_orientadores.sum()\n",
        "artigos_por_orientador = (orientador_proportions * 20).round().astype(int)\n",
        "\n",
        "TestTCCsDataset = pd.DataFrame()\n",
        "for orientador, num_artigos in artigos_por_orientador.items():\n",
        "    orientador_data = TCCsDataset[TCCsDataset['Orientador'] == orientador].sample(n=num_artigos, random_state=13)\n",
        "    TestTCCsDataset = pd.concat([TestTCCsDataset, orientador_data])\n",
        "\n",
        "\n",
        "#PREPARAÇÃO DO DATAFRAME DE TREINO\n",
        "indices_itens_teste = TCCsDataset.index.isin(TestTCCsDataset.index)\n",
        "TrainTCCsDataset = TCCsDataset[~indices_itens_teste]\n",
        "\n",
        "#NOVO DATAFRAME DE TESTE: TestTCCsDataset\n",
        "#NOVO DATAFRAME DE TREINO:\n",
        "TrainTCCsDataset"
      ],
      "metadata": {
        "id": "XMIqivSCeRhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A seguir, as mesmas etapas feitas anteriormente, entretando com apenas o dataframe de treino"
      ],
      "metadata": {
        "id": "Bdb3yRU_gWFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PontuacaoTrainTCC = TrainTCCsDataset\n",
        "dataset_columns = PontuacaoTrainTCC.columns[2:]\n",
        "dataset_columns\n",
        "\n",
        "total_professores = {}\n",
        "\n",
        "for index, row in PontuacaoTrainTCC.iterrows():\n",
        "  orientador = row['Orientador']\n",
        "  coorientador = row['Coorientador']\n",
        "\n",
        "\n",
        "  if orientador not in total_professores:\n",
        "    total_professores[orientador] = {}\n",
        "    total_professores[orientador] = row[dataset_columns]\n",
        "  elif orientador in total_professores:\n",
        "    total_professores[orientador] += row[dataset_columns]\n",
        "\n",
        "  if coorientador not in total_professores:\n",
        "    total_professores[coorientador] = {}\n",
        "    total_professores[coorientador] = row[dataset_columns]\n",
        "  elif coorientador in total_professores:\n",
        "    total_professores[coorientador] += row[dataset_columns]\n",
        "\n",
        "\n",
        "train_orientadores_df = pd.DataFrame(total_professores)\n",
        "train_orientadores_df = train_orientadores_df.drop(columns = '-', axis=1)\n",
        "\n",
        "train_orientadores_df"
      ],
      "metadata": {
        "id": "sgRZqqU0fhBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PontuacaoTrainTCC = train_orientadores_df\n",
        "\n",
        "def calcular_porcentagem(linha):\n",
        "    soma = linha.sum()\n",
        "    if soma == 0:\n",
        "        return linha\n",
        "    return (linha / soma)\n",
        "\n",
        "dataset_columns = PontuacaoTrainTCC.apply(calcular_porcentagem, axis=1)\n",
        "\n",
        "\n",
        "TrainDataframe = dataset_columns.transpose()\n",
        "TrainDataframe = TrainDataframe + 0.001\n",
        "TrainDataframe"
      ],
      "metadata": {
        "id": "-LA_5yx5gB0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "professores = list(set(TrainDataframe.index))\n",
        "topicos = list(set(TrainDataframe.columns))\n",
        "\n",
        "colunas = pd.MultiIndex.from_product([topicos, ['Participação', 'Horas Ministradas']])\n",
        "\n",
        "TeachersCrossMerged = pd.DataFrame(1, index=professores, columns=colunas)\n",
        "\n",
        "for professor in professores:\n",
        "  for topico in topicos:\n",
        "    if topico in TrainDataframe.columns and professor in TrainDataframe.index:\n",
        "      tcc_value = TrainDataframe.at[professor, topico]\n",
        "      TeachersCrossMerged.at[professor, (topico, 'Participação')] = tcc_value\n",
        "    if topico in TopicosHorasDataframe.columns and professor in TopicosHorasDataframe.index:\n",
        "      hours_value = TopicosHorasDataframe.at[professor, topico]\n",
        "      TeachersCrossMerged.at[professor, (topico, 'Horas Ministradas')] = hours_value\n",
        "\n",
        "TeachersCrossMerged"
      ],
      "metadata": {
        "id": "H-seiqj2kn9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GERAR A RECOMENDAÇÃO\n",
        "def gerar_recomendacao1(assunto1, assunto2, assunto3):\n",
        "  recomendacao = {}\n",
        "  for index, row in TeachersCrossMerged.iterrows():\n",
        "    P_Assunto1 = TeachersCrossMerged.loc[index, (assunto1, 'Participação')]\n",
        "    H_Assunto1 = TeachersCrossMerged.loc[index, (assunto1, 'Horas Ministradas')]\n",
        "\n",
        "    P_Assunto2 = TeachersCrossMerged.loc[index, (assunto2, 'Participação')]\n",
        "    H_Assunto2 = TeachersCrossMerged.loc[index, (assunto2, 'Horas Ministradas')]\n",
        "\n",
        "    P_Assunto3 = TeachersCrossMerged.loc[index, (assunto3, 'Participação')]\n",
        "    H_Assunto3 = TeachersCrossMerged.loc[index, (assunto3, 'Horas Ministradas')]\n",
        "\n",
        "\n",
        "    P_total = df_porcentagens_orientadores.at[index, 'Porcentagem de Aparição']\n",
        "\n",
        "    P = P_total * P_Assunto1 * P_Assunto2 * P_Assunto3 * H_Assunto1 * H_Assunto2 * H_Assunto3\n",
        "    recomendacao[index] = P\n",
        "\n",
        "  return recomendacao\n"
      ],
      "metadata": {
        "id": "GiPXqHSVgUBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def algoritmo_recomendacao1(assunto1, assunto2, assunto3, qtd):\n",
        "  previsao = gerar_recomendacao1(assunto1, assunto2, assunto3)\n",
        "  series = pd.Series(previsao)\n",
        "  melhores_professores = series.nlargest(qtd)\n",
        "  return melhores_professores\n"
      ],
      "metadata": {
        "id": "ts6UkFOSirax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TestDataset = TestTCCsDataset.drop('Orientador', axis=1)\n",
        "TestDataset = TestDataset.drop('Coorientador', axis=1)\n",
        "TestTCCsDataset"
      ],
      "metadata": {
        "id": "91tc9TtXhlS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top3_cols(row):\n",
        "    top3 = row.nlargest(3)\n",
        "    return top3.index\n",
        "\n",
        "mainSubject = TestDataset.apply(top3_cols, axis=1)\n",
        "mainSubject"
      ],
      "metadata": {
        "id": "TM_kYnG1hNdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teste de acurácia com o dataset de teste"
      ],
      "metadata": {
        "id": "__r5Nf97gq8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def teste_acuracia(n_professores):\n",
        "  contador = 0\n",
        "  for index, row in TestTCCsDataset.iterrows():\n",
        "    assunto = mainSubject[index]\n",
        "    assunto_1 = assunto[0]\n",
        "    assunto_2 = assunto[1]\n",
        "    assunto_3 = assunto[2]\n",
        "    orientador = TestTCCsDataset.loc[index,'Orientador']\n",
        "    coorientador = TestTCCsDataset.loc[index,'Coorientador']\n",
        "\n",
        "    recomendacao = algoritmo_recomendacao1(assunto_1, assunto_2, assunto_3, n_professores)\n",
        "    if orientador in recomendacao.index:\n",
        "      contador += 1\n",
        "    else:\n",
        "      if coorientador in recomendacao.index:\n",
        "        contador += 1\n",
        "\n",
        "  tamanho = TestTCCsDataset.shape\n",
        "  print(\"Levando em conta os \", n_professores,\" melhores: Dentre os\", tamanho[0],\", o algorítimo acertou\", contador)\n",
        "\n",
        "  acuracia = contador/tamanho[0]\n",
        "  print(\"A acurácia foi de:\", acuracia)"
      ],
      "metadata": {
        "id": "icfeiGITnsHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teste_acuracia(1)\n",
        "teste_acuracia(2)\n",
        "teste_acuracia(3)\n",
        "teste_acuracia(4)\n",
        "teste_acuracia(5)"
      ],
      "metadata": {
        "id": "ob9EAkxkpUOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CrossValidation"
      ],
      "metadata": {
        "id": "cA654bP8cjNp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SEPARAÇÃO DO DATAFRAME EM 4 FOLDS"
      ],
      "metadata": {
        "id": "HV_jld7KfZ7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TCCsDataset"
      ],
      "metadata": {
        "id": "CVZNZTcXGzT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PRIMEIRO FOLD\n",
        "contagem_orientadores = {}\n",
        "contagem_orientadores = TCCsDataset['Orientador'].value_counts()\n",
        "\n",
        "FoldTCCsDataset1 = {}\n",
        "\n",
        "orientador_proportions = contagem_orientadores / contagem_orientadores.sum()\n",
        "artigos_por_orientador = (orientador_proportions * 41).round().astype(int)\n",
        "FoldTCCsDataset1 = pd.DataFrame()\n",
        "\n",
        "for orientador, num_artigos in artigos_por_orientador.items():\n",
        "    orientador_data = TCCsDataset[TCCsDataset['Orientador'] == orientador].sample(n=num_artigos, random_state=13)\n",
        "    FoldTCCsDataset1 = pd.concat([FoldTCCsDataset1, orientador_data])\n",
        "\n",
        "#PREPARAÇÃO DO RESTANTE DO DATAFRAME DE TREINO\n",
        "indices_itens_teste = TCCsDataset.index.isin(FoldTCCsDataset1.index)\n",
        "SplitTCCsDataset1 = TCCsDataset[~indices_itens_teste]\n",
        "\n",
        "FoldTCCsDataset1.shape"
      ],
      "metadata": {
        "id": "EkUTlDt4crGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SEGUNDO FOLD\n",
        "contagem_orientadores = {}\n",
        "contagem_orientadores = SplitTCCsDataset1['Orientador'].value_counts()\n",
        "\n",
        "FoldTCCsDataset2 = {}\n",
        "\n",
        "orientador_proportions = contagem_orientadores / contagem_orientadores.sum()\n",
        "artigos_por_orientador = (orientador_proportions * 22).round().astype(int)\n",
        "FoldTCCsDataset2 = pd.DataFrame()\n",
        "\n",
        "for orientador, num_artigos in artigos_por_orientador.items():\n",
        "    orientador_data = SplitTCCsDataset1[SplitTCCsDataset1['Orientador'] == orientador].sample(n=num_artigos, random_state=13)\n",
        "    FoldTCCsDataset2 = pd.concat([FoldTCCsDataset2, orientador_data])\n",
        "\n",
        "#PREPARAÇÃO DO RESTANTE DO DATAFRAME DE TREINO\n",
        "indices_itens_teste = SplitTCCsDataset1.index.isin(FoldTCCsDataset2.index)\n",
        "SplitTCCsDataset2 = SplitTCCsDataset1[~indices_itens_teste]\n",
        "\n",
        "FoldTCCsDataset2.shape"
      ],
      "metadata": {
        "id": "kUWWqrQ8es5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TERCEIRO FOLD\n",
        "contagem_orientadores = {}\n",
        "contagem_orientadores = FoldTCCsDataset1['Orientador'].value_counts()\n",
        "\n",
        "FoldTCCsDataset3 = {}\n",
        "\n",
        "orientador_proportions = contagem_orientadores / contagem_orientadores.sum()\n",
        "artigos_por_orientador = (orientador_proportions * 21).round().astype(int)\n",
        "FoldTCCsDataset3 = pd.DataFrame()\n",
        "\n",
        "for orientador, num_artigos in artigos_por_orientador.items():\n",
        "    orientador_data = FoldTCCsDataset1[FoldTCCsDataset1['Orientador'] == orientador].sample(n=num_artigos, random_state=13)\n",
        "    FoldTCCsDataset3 = pd.concat([FoldTCCsDataset3, orientador_data])\n",
        "\n",
        "#PREPARAÇÃO DO RESTANTE DO DATAFRAME DE TREINO\n",
        "indices_itens_teste = FoldTCCsDataset1.index.isin(FoldTCCsDataset3.index)\n",
        "SplitTCCsDataset3 = FoldTCCsDataset1[~indices_itens_teste]\n",
        "\n",
        "FoldTCCsDataset3.shape"
      ],
      "metadata": {
        "id": "DR4IB_GogdWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SplitTCCsDataset2"
      ],
      "metadata": {
        "id": "cERuelYPTANR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Organizar folds\n",
        "print(SplitTCCsDataset3.shape, FoldTCCsDataset2.shape, FoldTCCsDataset3.shape, SplitTCCsDataset2.shape)"
      ],
      "metadata": {
        "id": "FRkZ4q3sSVh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FoldTCCsDataset1 = SplitTCCsDataset3\n",
        "FoldTCCsDataset2 = FoldTCCsDataset2\n",
        "FoldTCCsDataset3 = FoldTCCsDataset3\n",
        "FoldTCCsDataset4 = SplitTCCsDataset2"
      ],
      "metadata": {
        "id": "2TZXTm_Ug0aD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(FoldTCCsDataset1.shape, FoldTCCsDataset2.shape, FoldTCCsDataset3.shape, FoldTCCsDataset4.shape)"
      ],
      "metadata": {
        "id": "TJlsTKEZjdA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def algoritmo_naive_bayes(trainDataframe, testDataframe, peso_hora, peso_orientacao):\n",
        "  PontuacaoTCC = trainDataframe\n",
        "  dataset_columns = PontuacaoTCC.columns[2:]\n",
        "  dataset_columns\n",
        "\n",
        "  total_professores = {}\n",
        "\n",
        "  for index, row in PontuacaoTCC.iterrows():\n",
        "    orientador = row['Orientador']\n",
        "    coorientador = row['Coorientador']\n",
        "\n",
        "\n",
        "    if orientador not in total_professores:\n",
        "      total_professores[orientador] = {}\n",
        "      total_professores[orientador] = row[dataset_columns]\n",
        "    elif orientador in total_professores:\n",
        "      total_professores[orientador] += row[dataset_columns]\n",
        "\n",
        "    if coorientador not in total_professores:\n",
        "      total_professores[coorientador] = {}\n",
        "      total_professores[coorientador] = row[dataset_columns]\n",
        "    elif coorientador in total_professores:\n",
        "      total_professores[coorientador] += row[dataset_columns]\n",
        "\n",
        "\n",
        "  total_orientadores_df = pd.DataFrame(total_professores)\n",
        "  total_orientadores_df = total_orientadores_df.drop(columns = '-', axis=1)\n",
        "\n",
        "  PontuacaoTCC = total_orientadores_df\n",
        "\n",
        "  def calcular_porcentagem(linha):\n",
        "      soma = linha.sum()\n",
        "      if soma == 0:\n",
        "          return linha\n",
        "      return (linha / soma)\n",
        "\n",
        "  dataset_columns = PontuacaoTCC.apply(calcular_porcentagem, axis=1)\n",
        "\n",
        "  Database = dataset_columns.transpose()\n",
        "  Database = Database + 0.001\n",
        "\n",
        "  #DATASET HORAS\n",
        "  professores = list(set(Database.index))\n",
        "  topicos = list(set(Database.columns))\n",
        "\n",
        "  colunas = pd.MultiIndex.from_product([topicos, ['Participação', 'Horas Ministradas']])\n",
        "\n",
        "  TeachersCrossMerged = pd.DataFrame(1, index=professores, columns=colunas)\n",
        "\n",
        "  for professor in professores:\n",
        "    for topico in topicos:\n",
        "      if topico in Database.columns and professor in Database.index:\n",
        "        tcc_value = Database.at[professor, topico]\n",
        "        TeachersCrossMerged.at[professor, (topico, 'Participação')] = tcc_value\n",
        "      if topico in TopicosHorasDataframe.columns and professor in TopicosHorasDataframe.index:\n",
        "        hours_value = TopicosHorasDataframe.at[professor, topico]\n",
        "        TeachersCrossMerged.at[professor, (topico, 'Horas Ministradas')] = hours_value\n",
        "\n",
        "  TeachersCrossMerged\n",
        "\n",
        "\n",
        "  #Algoritmo\n",
        "  def algoritmo(assunto1, assunto2, assunto3):\n",
        "    recomendacao = {}\n",
        "    for index, row in TeachersCrossMerged.iterrows():\n",
        "      P_Assunto1 = TeachersCrossMerged.loc[index, (assunto1, 'Participação')] * peso_orientacao\n",
        "      H_Assunto1 = TeachersCrossMerged.loc[index, (assunto1, 'Horas Ministradas')] * peso_hora\n",
        "\n",
        "      P_Assunto2 = TeachersCrossMerged.loc[index, (assunto2, 'Participação')] * peso_orientacao\n",
        "      H_Assunto2 = TeachersCrossMerged.loc[index, (assunto2, 'Horas Ministradas')] * peso_hora\n",
        "\n",
        "      P_Assunto3 = TeachersCrossMerged.loc[index, (assunto3, 'Participação')] * peso_orientacao\n",
        "      H_Assunto3 = TeachersCrossMerged.loc[index, (assunto3, 'Horas Ministradas')] * peso_hora\n",
        "\n",
        "      P_total = df_porcentagens_orientadores.at[index, 'Porcentagem de Aparição']\n",
        "\n",
        "      if H_Assunto1 == 0:\n",
        "        P = P_total * P_Assunto1 * P_Assunto2 * P_Assunto3\n",
        "        recomendacao[index] = P\n",
        "      elif P_Assunto1 == 0:\n",
        "        P = P_total * H_Assunto1 * H_Assunto2 * H_Assunto3\n",
        "        recomendacao[index] = P\n",
        "      else:\n",
        "        P = P_total * P_Assunto1 * P_Assunto2 * P_Assunto3 * H_Assunto1 * H_Assunto2 * H_Assunto3\n",
        "        recomendacao[index] = P\n",
        "\n",
        "    return recomendacao\n",
        "\n",
        "  #CHAMA A FUNÇÃO E TRAZ OS 5 PROFESSORES COM MAIOR PROBABILIDADE\n",
        "  def funcao_calc(assunto1, assunto2, assunto3, qtd):\n",
        "    previsao = algoritmo(assunto1, assunto2, assunto3)\n",
        "    series = pd.Series(previsao)\n",
        "    melhores_professores = series.nlargest(qtd)\n",
        "    return melhores_professores\n",
        "\n",
        "  TestDataset = testDataframe.drop('Orientador', axis=1)\n",
        "  TestDataset = TestDataset.drop('Coorientador', axis=1)\n",
        "\n",
        "  #TRAZ OS 3 PRINCIPAIS TEMAS DO TCC\n",
        "  def top3_cols(row):\n",
        "    top3 = row.nlargest(3)\n",
        "    return top3.index\n",
        "\n",
        "  mainSubject = TestDataset.apply(top3_cols, axis=1)\n",
        "\n",
        "  #CHAMA A FUNÇÃO PARA CALCULAR A ACURÁCIA\n",
        "  def teste_validacao(n_professores):\n",
        "    contador = 0\n",
        "    for index, row in testDataframe.iterrows():\n",
        "      assunto = mainSubject[index]\n",
        "      assunto_1 = assunto[0]\n",
        "      assunto_2 = assunto[1]\n",
        "      assunto_3 = assunto[2]\n",
        "      orientador = testDataframe.loc[index,'Orientador']\n",
        "      coorientador = testDataframe.loc[index,'Coorientador']\n",
        "\n",
        "      recomendacao = funcao_calc(assunto_1, assunto_2, assunto_3, n_professores)\n",
        "      if orientador in recomendacao.index:\n",
        "        contador += 1\n",
        "      elif coorientador in recomendacao.index:\n",
        "        contador += 1\n",
        "      # return (recomendacao,orientador)\n",
        "\n",
        "    tamanho = testDataframe.shape\n",
        "    print(\"Levando em conta os \", n_professores,\" melhores: Dentre os\", tamanho[0],\", o algorítimo acertou\", contador)\n",
        "    acuracia = contador/tamanho[0]\n",
        "    print(\"A acurácia foi de:\", acuracia)\n",
        "\n",
        "  teste_validacao(1)\n",
        "  teste_validacao(2)\n",
        "  teste_validacao(3)\n",
        "  teste_validacao(4)\n",
        "  teste_validacao(5)\n"
      ],
      "metadata": {
        "id": "Q6T1cg6ikcw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crossValidation(peso_hours, peso_orientation):\n",
        "  print('Utilizando preso hora:', peso_hours, 'peso orientacao:', peso_orientation)\n",
        "\n",
        "  round1TrainDataframe = {}\n",
        "  round1TrainDataframe = pd.concat([FoldTCCsDataset2, FoldTCCsDataset3, FoldTCCsDataset4])\n",
        "  round1TestDataframe = {}\n",
        "  round1TestDataframe = FoldTCCsDataset1\n",
        "\n",
        "  round2TrainDataframe = {}\n",
        "  round2TrainDataframe = pd.concat([FoldTCCsDataset1, FoldTCCsDataset3, FoldTCCsDataset4])\n",
        "  round2TestDataframe = {}\n",
        "  round2TestDataframe = FoldTCCsDataset2\n",
        "\n",
        "  round3TrainDataframe = {}\n",
        "  round3TrainDataframe = pd.concat([FoldTCCsDataset1, FoldTCCsDataset2, FoldTCCsDataset4])\n",
        "  round3TestDataframe = {}\n",
        "  round3TestDataframe = FoldTCCsDataset3\n",
        "\n",
        "  round4TrainDataframe = {}\n",
        "  round4TrainDataframe = pd.concat([FoldTCCsDataset1, FoldTCCsDataset2, FoldTCCsDataset3])\n",
        "  round4TestDataframe = {}\n",
        "  round4TestDataframe = FoldTCCsDataset4\n",
        "\n",
        "  print(\"Primeira Rodada:\")\n",
        "  algoritmo_naive_bayes(round1TrainDataframe, round1TestDataframe, peso_hours, peso_orientation)\n",
        "\n",
        "  print(\"Segunda Rodada:\")\n",
        "  algoritmo_naive_bayes(round2TrainDataframe, round2TestDataframe, peso_hours, peso_orientation)\n",
        "\n",
        "  print(\"Terceira Rodada:\")\n",
        "  algoritmo_naive_bayes(round3TrainDataframe, round3TestDataframe, peso_hours, peso_orientation)\n",
        "\n",
        "  print(\"Quarta Rodada:\")\n",
        "  algoritmo_naive_bayes(round4TrainDataframe, round4TestDataframe, peso_hours, peso_orientation)\n"
      ],
      "metadata": {
        "id": "s6d-G2agjqGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crossValidation(1, 0)"
      ],
      "metadata": {
        "id": "CNP9rxadoT3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crossValidation(0.75, 0.25)"
      ],
      "metadata": {
        "id": "tfdJaOiooUG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crossValidation(0.5, 0.5)"
      ],
      "metadata": {
        "id": "RqFfRb7DomwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crossValidation(0.25, 0.75)"
      ],
      "metadata": {
        "id": "fCNwj3o7opPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crossValidation(0, 1)"
      ],
      "metadata": {
        "id": "x80h9fvyosr_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}